{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkNawk/CHyDfroTXjsYlkb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["appname = \"EDA Example\"\n","\n","# Look into https://spark.apache.org/downloads.html for the latest version\n","spark_mirror = \"https://mirrors.sonic.net/apache/spark\"\n","spark_version = \"3.3.1\"\n","hadoop_version = \"3\"\n","\n","# Install Java 8 (Spark does not work with newer Java versions)\n","! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Download and extract Spark binary distribution\n","! rm -rf spark-{spark_version}-bin-hadoop{hadoop_version}.tgz spark-{spark_version}-bin-hadoop{hadoop_version}\n","! wget -q {spark_mirror}/spark-{spark_version}/spark-{spark_version}-bin-hadoop{hadoop_version}.tgz\n","! tar xzf spark-{spark_version}-bin-hadoop{hadoop_version}.tgz\n","\n","# The only 2 environment variables needed to set up Java and Spark\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/spark-{spark_version}-bin-hadoop{hadoop_version}\"\n","\n","# Set up the Spark environment based on the environment variable SPARK_HOME \n","! pip install -q findspark\n","import findspark\n","findspark.init()\n","\n","# Get the Spark session object (basic entry point for every operation)\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(appname).master(\"local[*]\").getOrCreate()"],"metadata":{"id":"Jy6gEx9gr2Ei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark import SparkFiles\n","spark.sparkContext.addFile('https://github.com/apache/spark/blob/master/data/mllib/sample_linear_regression_data.txt')\n","df = spark.read.options(inferSchema='True', header='True').csv(SparkFiles.get('sample_linear_regression_data.txt'))"],"metadata":{"id":"LmmGN-LCrxYv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BMW3kN8rrx2"},"outputs":[],"source":["from pyspark.ml.regression import LinearRegression\n","\n","# Load training data\n","training = spark.read.format(\"libsvm\")\\\n","    .load(\"data/mllib/sample_linear_regression_data.txt\")\n","\n","lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","\n","# Fit the model\n","lrModel = lr.fit(training)\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"JRQyIA14UVcO"}},{"cell_type":"code","source":["# Print the coefficients and intercept for linear regression\n","print(\"Coefficients: %s\" % str(lrModel.coefficients))\n","print(\"Intercept: %s\" % str(lrModel.intercept))"],"metadata":{"id":"FgGzdz8YwTMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lrModel.transform(training).show()"],"metadata":{"id":"cnFSDDgZu8rZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the model over the training set and print out some metrics\n","trainingSummary = lrModel.summary\n","print(\"numIterations: %d\" % trainingSummary.totalIterations)\n","print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n","trainingSummary.residuals.show()\n","print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n","print(\"r2: %f\" % trainingSummary.r2)"],"metadata":{"id":"97MWB34BwQxe"},"execution_count":null,"outputs":[]}]}